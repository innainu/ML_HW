{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import cross_validation\n",
    "import sklearn as skl\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Gensim features\n",
    "# import gensim\n",
    "# from gensim import matutils\n",
    "# model = gensim.models.word2vec.Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "gensim_features = np.load(\"gensim_features.npy\")\n",
    "imgs = np.load(\"imgs.npy\")\n",
    "captions = np.load(\"captions.npy\")\n",
    "unique_lab = np.load(\"unique_lab.npy\")\n",
    "output = np.load(\"output.npy\")\n",
    "\n",
    "# Helper Functions\n",
    "\n",
    "\n",
    "def n_similarity(model, ws1, ws2):\n",
    "    v1 = []\n",
    "    v2 = []\n",
    "    bad_words = []\n",
    "    for word in ws1:\n",
    "        try: \n",
    "            v1.append(model[word])\n",
    "        except:\n",
    "            bad_words.append(word)\n",
    "            continue\n",
    "    for word in ws2:\n",
    "        try: \n",
    "            v2.append(model[word])\n",
    "        except:\n",
    "            bad_words.append(word)\n",
    "            continue\n",
    "    return np.dot(matutils.unitvec(np.array(v1).mean(axis=0)), matutils.unitvec(np.array(v2).mean(axis=0))), bad_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gensim_features = np.load(\"gensim_features.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get images and labels from 10k images\n",
    "labels_10k = []\n",
    "labels_scores = []\n",
    "for image in gensim_features:\n",
    "    img_idx = np.argmax(image)\n",
    "    labels_10k.append(unique_lab[np.argmax(image)])\n",
    "    labels_scores.append(np.max(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alexnet features\n",
    "alex_net_feat_10k = np.load(\"CS5785-final-data/alexnet_feat_10k.npy\")\n",
    "alexnet_train_imgs = np.load(\"CS5785-final-data/alexnet_feat_train.npy\")\n",
    "alexnet_feat_test = np.load(\"CS5785-final-data/alexnet_feat_test.npy\")\n",
    "alexnet_feat_train = np.load(\"CS5785-final-data/alexnet_feat_train.npy\")\n",
    "\n",
    "# sift features\n",
    "sift_feat_10k = np.load(\"CS5785-final-data/SIFTBoW_10k.npy\")\n",
    "sift_feat_train = np.load(\"CS5785-final-data/SIFTBoW_train.npy\")\n",
    "sift_feat_test = np.load(\"CS5785-final-data/SIFTBoW_test.npy\")\n",
    "\n",
    "# attributes features\n",
    "def read_att(file):\n",
    "    with open(file, 'r') as f:\n",
    "        reader = csv.reader(f, dialect='excel', delimiter='\\n')\n",
    "        img = []\n",
    "        fv = []\n",
    "        for row in reader: \n",
    "            img.append(row[0].split()[0])\n",
    "            fv.append(map(int, row[0].split()[1].split(\",\")))\n",
    "    return img, fv\n",
    "\n",
    "_, attributes_feat_train = read_att(\"CS5785-final-data/attributes_train.txt\")\n",
    "_, attributes_feat_test = read_att(\"CS5785-final-data/attributes_test.txt\")\n",
    "attributes_feat_train = np.array(attributes_feat_train)\n",
    "attributes_feat_test = np.array(attributes_feat_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get attributes list\n",
    "attributes_words = []\n",
    "with open(\"CS5785-final-data/attributes_list.txt\", 'r') as f:\n",
    "    for row in f:\n",
    "        row = row.encode('ascii','ignore')\n",
    "        row = row.translate(None, string.punctuation)\n",
    "        row = row.split()\n",
    "        attributes_words.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get gensim attributes score\n",
    "gensim_attributes_train = np.zeros((attributes_feat_train.shape[0], 200))\n",
    "gensim_attributes_test = np.zeros((attributes_feat_test.shape[0], 200))\n",
    "for u_idx, u in enumerate(unique_lab):\n",
    "    u = u.split(' ')\n",
    "    for c_idx, c in enumerate(attributes_feat_train):\n",
    "        idx = np.where(c > 0)[0]\n",
    "        words = np.array(attributes_words)[idx]\n",
    "        all_words = []\n",
    "        for w in words:\n",
    "            all_words.extend(w)\n",
    "        \n",
    "        gensim_attributes_train[c_idx, u_idx], _ = n_similarity(model, all_words, u)\n",
    "        \n",
    "    for c_idx, c in enumerate(attributes_feat_test):\n",
    "        idx = np.where(c > 0)[0]\n",
    "        words = np.array(attributes_words)[idx]\n",
    "        all_words = []\n",
    "        for w in words:\n",
    "            all_words.extend(w)\n",
    "        \n",
    "        gensim_attributes_test[c_idx, u_idx], _ = n_similarity(model, all_words, u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(unique_lab[np.argmax(gensim_attributes_train, axis=1)] == output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"gensim_attributes_test.npy\",gensim_attributes_test)\n",
    "np.save(\"gensim_attributes_train.npy\",gensim_attributes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(attributes_words).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
