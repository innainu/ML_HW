{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import sklearn as skl\n",
    "import pickle\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Gensim features\n",
    "gensim_features = np.load(\"gensim_features.npy\")\n",
    "imgs = np.load(\"imgs.npy\")\n",
    "captions = np.load(\"captions.npy\")\n",
    "unique_lab = np.load(\"unique_lab.npy\")\n",
    "output = np.load(\"output.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  1046  from 10k with threshold  0.6\n"
     ]
    }
   ],
   "source": [
    "# Threshold gensim features\n",
    "threshold = .6\n",
    "labels_10k = []\n",
    "labels_scores = []\n",
    "for image in gensim_features:\n",
    "    img_idx = np.argmax(image)\n",
    "    labels_10k.append(unique_lab[np.argmax(image)])\n",
    "    labels_scores.append(np.max(image))\n",
    "    \n",
    "mask = np.where(np.array(labels_scores) > threshold)[0]\n",
    "print 'Using ', len(mask), ' from 10k with threshold ', threshold\n",
    "\n",
    "labels_10k = np.array(labels_10k)[mask]\n",
    "for r in xrange(len(labels_10k)):\n",
    "    if labels_10k[r] == 'video store':\n",
    "        labels_10k[r] = 'videostore'\n",
    "        \n",
    "# When training full model, use this version\n",
    "# full_indices = np.random.randint(0,output.shape[0], size=1500)\n",
    "\n",
    "# When cross validating, use this version\n",
    "# missing_labels =  set(output) - set(labels_10k)\n",
    "# full_indices = []\n",
    "# for m in missing_labels:\n",
    "#     full_indices.append(np.where(output == m)[0][0])\n",
    "    \n",
    "labels_10k_full = np.concatenate([labels_10k, output])\n",
    "# assert len(pd.unique(labels_10k_full)) == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alexnet features\n",
    "alex_net_feat_10k = np.load(\"CS5785-final-data/alexnet_feat_10k.npy\")\n",
    "alex_net_feat_10k = alex_net_feat_10k[mask]\n",
    "alexnet_train_imgs = np.load(\"CS5785-final-data/alexnet_feat_train.npy\")\n",
    "alexnet_feat_test = np.load(\"CS5785-final-data/alexnet_feat_test.npy\")\n",
    "\n",
    "alexnet_feat_train = np.load(\"CS5785-final-data/alexnet_feat_train.npy\")\n",
    "#with 10k data\n",
    "alexnet_feat_train = np.vstack((alex_net_feat_10k, alexnet_feat_train))\n",
    "#only 3k data\n",
    "alexnet_feat_train_orig = np.load(\"CS5785-final-data/alexnet_feat_train.npy\")\n",
    "\n",
    "# sift features\n",
    "sift_feat_10k = np.load(\"CS5785-final-data/SIFTBoW_10k.npy\")\n",
    "sift_feat_10k = sift_feat_10k[mask]\n",
    "sift_feat_train = np.load(\"CS5785-final-data/SIFTBoW_train.npy\")\n",
    "sift_feat_test = np.load(\"CS5785-final-data/SIFTBoW_test.npy\")\n",
    "sift_feat_train = np.vstack((sift_feat_10k, sift_feat_train))\n",
    "\n",
    "# attributes features\n",
    "def read_att(file):\n",
    "    with open(file, 'r') as f:\n",
    "        reader = csv.reader(f, dialect='excel', delimiter='\\n')\n",
    "        img = []\n",
    "        fv = []\n",
    "        for row in reader: \n",
    "            img.append(row[0].split()[0])\n",
    "            fv.append(map(int, row[0].split()[1].split(\",\")))\n",
    "    return img, fv\n",
    "\n",
    "_, attributes_feat_train = read_att(\"CS5785-final-data/attributes_train.txt\")\n",
    "_, attributes_feat_test = read_att(\"CS5785-final-data/attributes_test.txt\")\n",
    "attributes_feat_train = np.array(attributes_feat_train)\n",
    "attributes_feat_test = np.array(attributes_feat_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gensim attributes features\n",
    "gensim_attributes_test = np.load(\"gensim_attributes_test.npy\")\n",
    "gensim_attributes_train = np.load(\"gensim_attributes_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 200)\n",
      "(3000, 200)\n"
     ]
    }
   ],
   "source": [
    "print gensim_attributes_test.shape\n",
    "print gensim_attributes_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_feat_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(702, 4096)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet10k_full_feat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333083832335\n"
     ]
    }
   ],
   "source": [
    "#with word to vec .33\n",
    "#without word2vec .32\n",
    "\n",
    "##threshold .6\n",
    "alexnet_3k_log = SGDClassifier(loss='log', penalty='l1', n_jobs=-1, n_iter=10, random_state=1)\n",
    "\n",
    "an3k_feat_train, an3k_feat_test, an3k_y_train, an3k_y_test = train_test_split(alexnet_feat_train, labels_10k_full, test_size=0.33, random_state=42)\n",
    "alexnet_3k_log.fit(an3k_feat_train, an3k_y_train)\n",
    "pred_an3k = alexnet_3k_log.predict(an3k_feat_test)\n",
    "print np.sum(pred_an3k == an3k_y_test) / float(len(an3k_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2686868686868687"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "att_3k_fullclass = RandomForestClassifier(n_estimators=300, max_depth=100, random_state=1)\n",
    "att_feat_train, att_feat_test, att_y_train, att_y_test = train_test_split(attributes_feat_train, output, test_size=0.33, random_state=42)\n",
    "att_3k_fullclass.fit(att_feat_train, att_y_train)\n",
    "pred_att_3k_fullclass = att_3k_fullclass.predict(att_feat_test)\n",
    "np.sum(pred_att_3k_fullclass == att_y_test) / float(len(att_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alexnet 3k rfc model\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "alexnet_3k_rfc = RFC(n_estimators = 400 )\n",
    "# attributes rfc\n",
    "att_3k_rfc = RFC(n_estimators = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alexnet 3k model\n",
    "alexnet_3k_log = SGDClassifier(loss='log', penalty='elasticnet', n_jobs=-1)\n",
    "\n",
    "\n",
    "# sift 3k model\n",
    "sift_3k_log = SGDClassifier(loss='log', penalty='elasticnet', n_jobs=-1)\n",
    "\n",
    "# alexnet 10k + full class\n",
    "alexnet_10k_fullclass = SGDClassifier(loss='log', penalty='elasticnet', n_jobs=-1)\n",
    "\n",
    "# sift 10k + full class\n",
    "sift_10k_fullclass = SGDClassifier(loss='log', penalty='elasticnet', n_jobs=-1)\n",
    "\n",
    "# attributes\n",
    "att_3k_fullclass = SGDClassifier(loss='log', penalty='elasticnet', n_jobs=-1)\n",
    "\n",
    "# gensim attributes\n",
    "gensim_att_3k_fullclass = SGDClassifier(loss='log', penalty='elasticnet', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Att 3k fullclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=-1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train models\n",
    "att_feat_train, att_feat_test, att_y_train, att_y_test = train_test_split(attributes_feat_train, output, test_size=0.33, random_state=42)\n",
    "att_3k_fullclass.fit(att_feat_train, att_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_att_3k_fullclass = att_3k_fullclass.predict(att_feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21414141414141413"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pred_att_3k_fullclass == att_y_test) / float(len(att_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "att_3k_fullclass.fit(attributes_feat_train, output)\n",
    "\n",
    "pickle.dump( att_3k_fullclass, open( \"att_3k_fullclass.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim att 3k fullclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0424242424242\n"
     ]
    }
   ],
   "source": [
    "# train models\n",
    "gatt_feat_train, gatt_feat_test, gatt_y_train, gatt_y_test = train_test_split(gensim_attributes_train, output, test_size=0.33, random_state=42)\n",
    "gensim_att_3k_fullclass.fit(gatt_feat_train, gatt_y_train)\n",
    "pred_gatt_3k_fullclass = gensim_att_3k_fullclass.predict(gatt_feat_test)\n",
    "print np.sum(pred_gatt_3k_fullclass == gatt_y_test) / float(len(gatt_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gensim_att_3k_fullclass.fit(attributes_feat_train, output)\n",
    "pickle.dump( att_3k_fullclass, open( \"gensim_att_3k_fullclass.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### alexnet_3k_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.252525252525\n"
     ]
    }
   ],
   "source": [
    "# train models\n",
    "an3k_feat_train, an3k_feat_test, an3k_y_train, an3k_y_test = train_test_split(alexnet_feat_train, output, test_size=0.33, random_state=42)\n",
    "alexnet_3k_log.fit(an3k_feat_train, an3k_y_train)\n",
    "pred_an3k = alexnet_3k_log.predict(an3k_feat_test)\n",
    "print np.sum(pred_an3k == an3k_y_test) / float(len(an3k_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alexnet_3k_log.fit(alexnet_feat_train, output)\n",
    "pickle.dump( alexnet_3k_log, open( \"alexnet_3k_fullclass.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sift_3k_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.069696969697\n"
     ]
    }
   ],
   "source": [
    "sift3k_feat_train, sift3k_feat_test, sift3k_y_train, sift3k_y_test = train_test_split(sift_feat_train, output, test_size=0.33, random_state=42)\n",
    "sift_3k_log.fit(sift3k_feat_train, sift3k_y_train)\n",
    "pred_sift3k = sift_3k_log.predict(sift3k_feat_test)\n",
    "print np.sum(pred_sift3k == sift3k_y_test) / float(len(sift3k_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sift_3k_log.fit(sift_feat_train, output)\n",
    "pickle.dump(sift_3k_log, open( \"sift_3k_fullclass.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alexnet 10k + full class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 10k train:  0.35754985755\n",
      "Accuracy on 3k train:  0.0733333333333\n"
     ]
    }
   ],
   "source": [
    "alexnet10k_full_feat_train, alexnet10k_full_feat_test, alexnet10k_full_y_train, alexnet10k_full_y_test = \\\n",
    "        train_test_split(alex_net_feat_10k, labels_10k_full, test_size=0.33, random_state=42)\n",
    "alexnet_10k_fullclass.fit(alexnet10k_full_feat_train, alexnet10k_full_y_train)\n",
    "pred_alexnet_10k_full = alexnet_10k_fullclass.predict(alexnet10k_full_feat_test)\n",
    "print 'Accuracy on 10k train: ', np.sum(pred_alexnet_10k_full == alexnet10k_full_y_test) / \\\n",
    "        float(len(alexnet10k_full_y_test))\n",
    "\n",
    "pred_alexnet_10k_full = alexnet_10k_fullclass.predict(alexnet_feat_train)\n",
    "print 'Accuracy on 3k train: ', np.sum(pred_alexnet_10k_full == output) / float(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alexnet_10k_fullclass.fit(alex_net_feat_10k, labels_10k_full)\n",
    "pickle.dump( alexnet_10k_fullclass, open( \"alexnet_10k_fullclass.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sift 10k + full class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11396011396\n"
     ]
    }
   ],
   "source": [
    "sift10k_full_feat_train, sift10k_full_feat_test, sift10k_full_y_train, sift10k_full_y_test = train_test_split(sift_feat_10k, labels_10k_full, test_size=0.33, random_state=42)\n",
    "sift_10k_fullclass.fit(sift10k_full_feat_train, sift10k_full_y_train)\n",
    "pred_sift_10k_full = sift_10k_fullclass.predict(sift10k_full_feat_test)\n",
    "print np.sum(pred_sift_10k_full == sift10k_full_y_test) / float(len(sift10k_full_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 3k train:  0.042\n"
     ]
    }
   ],
   "source": [
    "pred_sift_10k_full = sift_10k_fullclass.predict(sift_feat_train)\n",
    "print 'Accuracy on 3k train: ', np.sum(pred_sift_10k_full == output) / float(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sift_10k_fullclass.fit(sift_feat_10k, labels_10k_full)\n",
    "pickle.dump( alexnet_10k_fullclass, open( \"sift_10k_fullclass.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rfc classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.323232323232\n"
     ]
    }
   ],
   "source": [
    "##rfc classifier on alexnet features only 3k\n",
    "alexnet_rfc_feat_train, alexnet_rfc_feat_test, alexnet_rfc_y_train, alexnet_rfc_y_test = train_test_split(alexnet_feat_train_orig, output, test_size=0.33, random_state=42)\n",
    "alexnet_3k_rfc.fit(alexnet_rfc_feat_train, alexnet_rfc_y_train)\n",
    "pred_alexnet_3k_rfc = alexnet_3k_rfc.predict(alexnet_rfc_feat_test)\n",
    "print np.sum(pred_alexnet_3k_rfc == alexnet_rfc_y_test) / float(len(alexnet_rfc_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.318862275449\n"
     ]
    }
   ],
   "source": [
    "alexnet_rfc_feat_train, alexnet_rfc_feat_test, alexnet_rfc_y_train, alexnet_rfc_y_test = train_test_split(alexnet_feat_train, labels_10k_full, test_size=0.33, random_state=42)\n",
    "alexnet_3k_rfc.fit(alexnet_rfc_feat_train, alexnet_rfc_y_train)\n",
    "pred_alexnet_3k_rfc = alexnet_3k_rfc.predict(alexnet_rfc_feat_test)\n",
    "print np.sum(pred_alexnet_3k_rfc == alexnet_rfc_y_test) / float(len(alexnet_rfc_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##rfc classifier on alexnet features only 3k\n",
    "alexnet_rfc_feat_train, alexnet_rfc_feat_test, alexnet_rfc_y_train, alexnet_rfc_y_test = train_test_split(alexnet_feat_train_orig, output, test_size=0.33, random_state=42)\n",
    "alexnet_3k_rfc.fit(alexnet_rfc_feat_train, alexnet_rfc_y_train)\n",
    "pred_alexnet_3k_rfc = alexnet_3k_rfc.predict(alexnet_rfc_feat_test)\n",
    "print np.sum(pred_alexnet_3k_rfc == alexnet_rfc_y_test) / float(len(alexnet_rfc_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.266666666667\n"
     ]
    }
   ],
   "source": [
    "##rfc classifier on attribute features only 3k\n",
    "att_rfc_feat_train, att_rfc_feat_test, att_rfc_y_train, att_rfc_y_test = train_test_split(attributes_feat_train, output, test_size=0.33, random_state=42)\n",
    "att_3k_rfc.fit(att_rfc_feat_train, att_rfc_y_train)\n",
    "pred_att_3k_rfc = att_3k_rfc.predict(att_rfc_feat_test)\n",
    "print np.sum(pred_att_3k_rfc == att_rfc_y_test) / float(len(att_rfc_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##meta model for rfc trained on atta nd rfc trained on att\n",
    "meta_model2 = RFC(n_estimators = 400)\n",
    "\n",
    "#predict for all training data\n",
    "f1 = alexnet_3k_rfc.predict_proba(alexnet_feat_train_orig)\n",
    "f2 = att_3k_rfc.predict_proba(attributes_feat_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 200)\n",
      "(3000, 200)\n"
     ]
    }
   ],
   "source": [
    "print f1.shape\n",
    "print f2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta_train_feats2 = np.concatenate((f1, f2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 400)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train_feats2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16464646464646465"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(meta_train_feats2, output, test_size=0.33, random_state=42)\n",
    "meta_model2.fit(x_train2, y_train2)\n",
    "np.sum(meta_model2.predict(x_test2) == y_test2) / float(len(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19595959595959597"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##meta model for naive bayes trained on atta nd rfc trained on att\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "meta_model3 = MNB()\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(meta_train_feats2, output, test_size=0.33, random_state=42)\n",
    "meta_model3.fit(x_train3, y_train3)\n",
    "np.sum(meta_model3.predict(x_test3) == y_test3) / float(len(y_test3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gensim_att_3k_fullclass = pickle.load( open( \"gensim_att_3k_fullclass.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta_model = SGDClassifier(loss='log', penalty='elasticnet', n_jobs=-1)\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(output)\n",
    "\n",
    "f1 = alexnet_3k_log.predict(alexnet_feat_train)\n",
    "f1= lb.transform(f1)\n",
    "\n",
    "f2 = sift_3k_log.predict_proba(sift_feat_train)\n",
    "\n",
    "f3 = alexnet_10k_fullclass.predict(alexnet_feat_train)\n",
    "f3 = lb.transform(f3)\n",
    "\n",
    "f4 = sift_10k_fullclass.predict_proba(sift_feat_train)\n",
    "\n",
    "f5 = att_3k_fullclass.predict_proba(attributes_feat_train)\n",
    "\n",
    "f6 = gensim_att_3k_fullclass.predict_proba(gensim_attributes_train)\n",
    "\n",
    "meta_train_feats = np.concatenate((f1, f2, f3, f4, f5, f6), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "f1_test = alexnet_3k_log.predict(alexnet_feat_test)\n",
    "f1_test= lb.transform(f1_test)\n",
    "f2_test = sift_3k_log.predict_proba(sift_feat_test)\n",
    "f3_test = alexnet_10k_fullclass.predict(alexnet_feat_test)\n",
    "f3_test = lb.transform(f3_test)\n",
    "f4_test = sift_10k_fullclass.predict_proba(sift_feat_test)\n",
    "f5_test = att_3k_fullclass.predict_proba(attributes_feat_test)\n",
    "f6_test = gensim_att_3k_fullclass.predict_proba(gensim_attributes_test)\n",
    "\n",
    "meta_test_feats = np.concatenate((f1_test, f2_test, f3_test, f4_test, f5_test, f6_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1200)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=-1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(meta_train_feats, output, test_size=0.33, random_state=42)\n",
    "meta_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99696969696969695"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(meta_model.predict(x_test) == y_test)/float(len(y_test))\n",
    "\n",
    "#33%"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_model.fit(meta_train_feats, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred1 = meta_model.predict(meta_test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = []\n",
    "with open(\"CS5785-final-data/test.txt\", 'r') as f:\n",
    "    reader = csv.reader(f, dialect='excel', delimiter='\\n')\n",
    "    for r in reader:\n",
    "        img.append(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"ID\": img})\n",
    "submission.loc[:,'Category'] = pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0000.jpg', '0001.jpg', '0002.jpg', ..., '0997.jpg', '0998.jpg',\n",
       "        '0999.jpg'],\n",
       "       ['lawn', 'badlands', 'roof', ..., 'bowling alley', 'jewelry shop',\n",
       "        'hayfield']], \n",
       "      dtype='|S22')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
